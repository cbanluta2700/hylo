name: Hylo Travel AI - Comprehensive CI/CD Pipeline

on:
  push:
    branches: [main, develop, 'feature/*', 'fix/*', 'hotfix/*']
  pull_request:
    branches: [main, develop]
  schedule:
    # Run performance tests weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run performance tests'
        required: false
        default: false
        type: boolean
      skip_cache:
        description: 'Skip cache restoration'
        required: false
        default: false
        type: boolean

env:
  # Performance testing configuration
  PERFORMANCE_THRESHOLD_P95: 2000
  PERFORMANCE_THRESHOLD_P99: 5000
  LOAD_TEST_DURATION: 300
  CONCURRENT_USERS: 50
  
  # CI configuration
  NODE_VERSION_MATRIX: '[16.x, 18.x, 20.x]'
  COVERAGE_THRESHOLD: 85
  CACHE_VERSION: 'v2'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  # ===== SETUP AND VALIDATION =====
  setup:
    name: 🚀 Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-keys.outputs.cache-key }}
      package-hash: ${{ steps.cache-keys.outputs.package-hash }}
      should-run-performance: ${{ steps.conditions.outputs.should-run-performance }}
      matrix-node-versions: ${{ steps.matrix.outputs.node-versions }}
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for performance comparison
      
      - name: 🔍 Generate cache keys
        id: cache-keys
        run: |
          PACKAGE_HASH=${{ hashFiles('**/package*.json', '**/yarn.lock', '**/pnpm-lock.yaml') }}
          CACHE_KEY="${{ env.CACHE_VERSION }}-${{ runner.os }}-deps-${PACKAGE_HASH}"
          
          echo "package-hash=${PACKAGE_HASH}" >> $GITHUB_OUTPUT
          echo "cache-key=${CACHE_KEY}" >> $GITHUB_OUTPUT
          echo "::notice::Cache key generated: ${CACHE_KEY}"
      
      - name: 🎯 Determine execution conditions
        id: conditions
        run: |
          SHOULD_RUN_PERFORMANCE="false"
          
          # Run performance tests if:
          # 1. Manually triggered with input
          # 2. Scheduled run (weekly)
          # 3. Push to main branch
          if [[ "${{ github.event.inputs.run_performance_tests }}" == "true" ]] || \
             [[ "${{ github.event_name }}" == "schedule" ]] || \
             [[ "${{ github.ref }}" == "refs/heads/main" && "${{ github.event_name }}" == "push" ]]; then
            SHOULD_RUN_PERFORMANCE="true"
          fi
          
          echo "should-run-performance=${SHOULD_RUN_PERFORMANCE}" >> $GITHUB_OUTPUT
          echo "::notice::Performance tests will run: ${SHOULD_RUN_PERFORMANCE}"
      
      - name: 📊 Setup Node.js matrix
        id: matrix
        run: |
          # Dynamic matrix based on branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "node-versions=[\"16.x\", \"18.x\", \"20.x\"]" >> $GITHUB_OUTPUT
          else
            echo "node-versions=[\"18.x\", \"20.x\"]" >> $GITHUB_OUTPUT
          fi

  # ===== DEPENDENCY MANAGEMENT =====
  dependencies:
    name: 📦 Dependencies & Cache
    runs-on: ubuntu-latest
    needs: setup
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 🚀 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          registry-url: 'https://registry.npmjs.org'
      
      - name: 🎯 Restore dependency cache
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache/restore@v4
        id: cache-deps
        with:
          path: |
            node_modules
            ~/.npm
            ~/.cache/ms-playwright
            .next/cache
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ env.CACHE_VERSION }}-${{ runner.os }}-deps-
            ${{ env.CACHE_VERSION }}-${{ runner.os }}-
      
      - name: 📥 Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: |
          echo "::group::Installing dependencies"
          npm ci --prefer-offline --no-audit
          npx playwright install --with-deps chromium
          echo "::endgroup::"
      
      - name: 💾 Save dependency cache
        if: steps.cache-deps.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules
            ~/.npm
            ~/.cache/ms-playwright
            .next/cache
          key: ${{ needs.setup.outputs.cache-key }}
      
      - name: 📊 Dependency audit
        run: |
          echo "::group::Security audit"
          npm audit --audit-level moderate || echo "::warning::Security vulnerabilities found"
          echo "::endgroup::"

  # ===== PARALLEL TESTING MATRIX =====
  test-matrix:
    name: 🧪 Test Suite (Node ${{ matrix.node-version }})
    runs-on: ${{ matrix.os }}
    needs: [setup, dependencies]
    
    strategy:
      fail-fast: false
      matrix:
        node-version: ${{ fromJson(needs.setup.outputs.matrix-node-versions) }}
        os: [ubuntu-latest, windows-latest]
        exclude:
          # Exclude Windows for non-main branches to save resources
          - os: windows-latest
            node-version: ${{ github.ref != 'refs/heads/main' && '16.x' || '' }}
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 🚀 Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          registry-url: 'https://registry.npmjs.org'
      
      - name: 🎯 Restore dependency cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.npm
            ~/.cache/ms-playwright
            .next/cache
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
      
      - name: 🔍 TypeScript type checking
        run: |
          echo "::group::TypeScript compilation"
          npm run type-check
          echo "::endgroup::"
      
      - name: 🧪 Unit tests with coverage
        run: |
          echo "::group::Running unit tests"
          npm run test:unit -- --coverage --reporter=verbose
          echo "::endgroup::"
      
      - name: 📊 Upload coverage reports
        if: matrix.node-version == '20.x' && matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports-${{ github.run_id }}
          path: coverage/
          retention-days: 7
      
      - name: 🔗 Integration tests  
        if: matrix.node-version == '20.x'
        run: |
          echo "::group::Integration tests"
          npm run test:integration
          echo "::endgroup::"
      
      - name: 🎭 E2E tests (Ubuntu only)
        if: matrix.os == 'ubuntu-latest' && matrix.node-version == '20.x'
        run: |
          echo "::group::End-to-end tests"
          npm run test:e2e
          echo "::endgroup::"
      
      - name: 📈 Test results summary
        if: always()
        run: |
          echo "::group::Test Summary"
          echo "Node.js version: ${{ matrix.node-version }}"
          echo "Operating system: ${{ matrix.os }}"
          echo "Test status: ${{ job.status }}"
          echo "::endgroup::"

  # ===== CODE QUALITY & SECURITY =====
  quality:
    name: 🔍 Code Quality & Security
    runs-on: ubuntu-latest
    needs: [setup, dependencies]
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: 🚀 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
      
      - name: 🎯 Restore dependency cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.npm
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
      
      - name: 🔍 ESLint analysis
        run: |
          echo "::group::ESLint code analysis"
          npm run lint -- --format=json --output-file=eslint-results.json || true
          npm run lint
          echo "::endgroup::"
      
      - name: 🎨 Prettier formatting check
        run: |
          echo "::group::Code formatting validation"
          npm run format:check
          echo "::endgroup::"
      
      - name: 🛡️ Security vulnerability scan
        run: |
          echo "::group::Security scanning"
          npm audit --audit-level moderate
          echo "::endgroup::"
      
      - name: 📊 Upload quality reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports-${{ github.run_id }}
          path: |
            eslint-results.json
            coverage/
          retention-days: 7

  # ===== BUILD & ARTIFACT GENERATION =====
  build:
    name: 🏗️ Build & Artifacts
    runs-on: ubuntu-latest
    needs: [test-matrix, quality]
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 🚀 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
      
      - name: 🎯 Restore dependency cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.npm
            .next/cache
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
      
      - name: 🏗️ Build application
        run: |
          echo "::group::Building application"
          npm run build
          echo "::endgroup::"
      
      - name: 📦 Generate build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ github.run_id }}
          path: |
            dist/
            .next/
            !.next/cache
          retention-days: 30
      
      - name: 📊 Build size analysis
        run: |
          echo "::group::Bundle size analysis"
          if [ -d "dist" ]; then
            find dist -name "*.js" -exec ls -lh {} \; | head -10
          fi
          if [ -d ".next" ]; then
            du -sh .next/static/* 2>/dev/null || echo "No .next/static found"
          fi
          echo "::endgroup::"

  # ===== PERFORMANCE TESTING =====
  performance:
    name: 🚀 Performance Testing
    runs-on: ubuntu-latest
    needs: [setup, build]
    if: needs.setup.outputs.should-run-performance == 'true'
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 🚀 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
      
      - name: 🎯 Restore caches
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.npm
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
      
      - name: 📦 Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ github.run_id }}
      
      - name: 🚀 Start application for testing
        run: |
          echo "::group::Starting application"
          npm run preview &
          APP_PID=$!
          echo "APP_PID=$APP_PID" >> $GITHUB_ENV
          
          # Wait for application to be ready
          timeout 30 bash -c 'until curl -f http://localhost:4173/health 2>/dev/null; do sleep 1; done'
          echo "::endgroup::"
      
      - name: 📈 Performance benchmarks
        run: |
          echo "::group::Running performance tests"
          npm run test:performance
          echo "::endgroup::"
      
      - name: 📊 Load testing simulation
        run: |
          echo "::group::Load testing"
          npm run test:load
          echo "::endgroup::"
      
      - name: 📋 Performance baseline comparison
        run: |
          echo "::group::Performance comparison"
          if [ -f "performance-baseline.json" ]; then
            npm run compare:performance
          else
            echo "::notice::No baseline found, creating new baseline"
            cp performance-results.json performance-baseline.json
          fi
          echo "::endgroup::"
      
      - name: 📊 Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ github.run_id }}
          path: |
            performance-*.json
            load-test-results/
          retention-days: 90

      - name: 📊 Generate Test Reports
        if: always()
        run: |
          echo "::group::Generating comprehensive test reports"
          # Generate comprehensive test report
          node scripts/generate-test-report.js
          
          # Generate aggregated results
          node scripts/aggregate-test-results.js
          
          # Generate interactive dashboard
          node scripts/generate-test-dashboard.js
          echo "::endgroup::"
        env:
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF: ${{ github.ref }}
          GITHUB_PR_NUMBER: ${{ github.event.pull_request.number }}
          GITHUB_RUN_ID: ${{ github.run_id }}

      - name: 💬 Post PR Comment
        if: always() && github.event_name == 'pull_request'
        run: |
          echo "::group::Posting PR comment with test results"
          node scripts/generate-pr-comment.js
          echo "::endgroup::"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_PR_NUMBER: ${{ github.event.pull_request.number }}
          GITHUB_RUN_ID: ${{ github.run_id }}

      - name: 📄 Upload Test Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-${{ github.run_id }}
          path: |
            test-results/
            coverage/
            eslint-results.json
            performance-results/
          retention-days: 30
      
      - name: 🛑 Stop application
        if: always()
        run: |
          if [ -n "$APP_PID" ]; then
            kill $APP_PID || true
          fi

  # ===== DEPLOYMENT PREPARATION =====
  deploy-staging:
    name: 🚀 Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build, test-matrix, quality]
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 📦 Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ github.run_id }}
      
      - name: 🚀 Deploy to Vercel Staging
        run: |
          echo "::group::Deploying to staging"
          # Deployment logic would go here
          echo "::notice::Staging deployment would happen here"
          echo "::endgroup::"
      
      - name: 🔍 Deployment validation
        run: |
          echo "::group::Validating deployment"
          npm run validate:deployment
          echo "::endgroup::"
      
      - name: 🔍 Run Deployment Readiness Validation
        if: always()
        run: node scripts/validate-deployment-readiness.js --format=json > deployment-validation.json
        continue-on-error: true

      - name: 🏥 Run Health Monitoring Check
        if: always()
        run: node scripts/health-monitoring-system.js check > health-check.json 2>&1
        continue-on-error: true

      - name: 🎯 Run End-to-End Pipeline Tests
        run: |
          node scripts/end-to-end-pipeline-tester.js \
            --environment=staging \
            --testEnvironment=staging \
            --rollbackEnabled=false \
            --output=e2e-staging-results.json
        continue-on-error: true

      - name: 📊 Generate Comprehensive Validation Report
        if: always()
        run: |
          node scripts/validation-reporting-system.js \
            --format=both \
            --outputDir=pipeline-reports \
            --serviceName="${{ github.repository }}" \
            --environment="staging"
        continue-on-error: true

      - name: 📦 Upload Staging Validation Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: staging-validation-reports-${{ github.run_id }}
          path: |
            pipeline-reports/
            deployment-validation.json
            health-check.json
            e2e-staging-results.json
          retention-days: 30

  # ===== PRODUCTION DEPLOYMENT =====
  deploy-production:
    name: 🎯 Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging, performance]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 📦 Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ github.run_id }}
      
      - name: 🚀 Deploy to Production
        run: |
          echo "::group::Deploying to production"
          # Production deployment logic would go here
          echo "::notice::Production deployment would happen here"
          echo "::endgroup::"
      
      - name: 🔍 Health check
        run: |
          echo "::group::Production health check"
          npm run health:check
          echo "::endgroup::"
      
      - name: 🔍 Production Deployment Readiness Validation
        if: always()
        run: node scripts/validate-deployment-readiness.js --format=json --environment=production > production-deployment-validation.json
        continue-on-error: true

      - name: 🏥 Production Health Monitoring Check
        if: always()
        run: |
          node scripts/health-monitoring-system.js check \
            --environment=production \
            --serviceName="${{ github.repository }}" > production-health-check.json 2>&1
        continue-on-error: true

      - name: 🎯 Production End-to-End Pipeline Tests
        run: |
          node scripts/end-to-end-pipeline-tester.js \
            --environment=production \
            --testEnvironment=production \
            --rollbackEnabled=true \
            --baseUrl="${{ secrets.VERCEL_PRODUCTION_URL || 'https://hylo-travel-ai.vercel.app' }}" \
            --output=e2e-production-results.json
        continue-on-error: true

      - name: 📊 Generate Production Validation Report
        if: always()
        run: |
          node scripts/validation-reporting-system.js \
            --format=both \
            --outputDir=production-pipeline-reports \
            --serviceName="${{ github.repository }}" \
            --environment="production" \
            --includePerformanceMetrics=true \
            --includeSecurityScans=true
        continue-on-error: true

      - name: ⚠️ Check Rollback Status
        if: always()
        run: |
          if [ -f "e2e-production-results.json" ]; then
            ROLLBACK_TRIGGERED=$(node -pe "JSON.parse(require('fs').readFileSync('e2e-production-results.json', 'utf8')).rollback.triggered")
            if [ "$ROLLBACK_TRIGGERED" = "true" ]; then
              echo "::error::Production deployment was rolled back due to quality issues"
              exit 2
            fi
          fi

      - name: 📦 Upload Production Validation Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: production-validation-reports-${{ github.run_id }}
          path: |
            production-pipeline-reports/
            production-deployment-validation.json
            production-health-check.json
            e2e-production-results.json
          retention-days: 30

  # ===== NOTIFICATION & REPORTING =====
  report:
    name: 📊 Test Results & Reporting
    runs-on: ubuntu-latest
    needs: [test-matrix, quality, performance, deploy-staging, deploy-production]
    if: always()
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
      
      - name: 🚀 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
      
      - name: 📦 Restore dependency cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            ~/.npm
          key: deps-${{ github.sha }}
          fail-on-cache-miss: false
      
      - name: � Install dependencies (if needed)
        run: |
          if [ ! -d "node_modules" ]; then
            npm ci
          fi
      
      - name: �📊 Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: 📋 Generate Test Reports
        run: |
          echo "::group::Generating test reports"
          node scripts/generate-test-report.js
          echo "::endgroup::"
      
      - name: 📊 Generate Comprehensive Pipeline Report
        if: always()
        run: |
          echo "::group::Generating comprehensive pipeline report"
          node scripts/validation-reporting-system.js \
            --format=both \
            --outputDir=final-pipeline-reports \
            --serviceName="${{ github.repository }}" \
            --environment="ci-cd" \
            --includeMetrics=true \
            --includeHealthChecks=true \
            --includeSecurityScans=true \
            --includePerformanceMetrics=true \
            --generateArtifacts=true
          echo "::endgroup::"
      
      - name: 📋 Generate comprehensive summary report
        run: |
          echo "::group::Generating summary report"
          echo "## 📊 CI/CD Pipeline Results" > pipeline-report.md
          echo "" >> pipeline-report.md
          echo "### 🎯 Job Status Summary" >> pipeline-report.md
          echo "- **Test Matrix**: ${{ needs.test-matrix.result }}" >> pipeline-report.md
          echo "- **Code Quality**: ${{ needs.quality.result }}" >> pipeline-report.md
          echo "- **Performance**: ${{ needs.performance.result }}" >> pipeline-report.md
          echo "- **Staging Deploy**: ${{ needs.deploy-staging.result }}" >> pipeline-report.md
          echo "- **Production Deploy**: ${{ needs.deploy-production.result }}" >> pipeline-report.md
          echo "" >> pipeline-report.md
          echo "### 📈 Pipeline Metrics" >> pipeline-report.md
          echo "- **Run ID**: ${{ github.run_id }}" >> pipeline-report.md
          echo "- **Commit SHA**: ${{ github.sha }}" >> pipeline-report.md
          echo "- **Branch**: ${{ github.ref_name }}" >> pipeline-report.md
          echo "- **Triggered by**: ${{ github.actor }}" >> pipeline-report.md
          echo "" >> pipeline-report.md
          
          # Add validation report summaries if available
          if [ -d "artifacts" ]; then
            echo "### 🔍 Validation Results" >> pipeline-report.md
            
            # Find validation reports
            find artifacts -name "*.json" -path "*/pipeline-reports/*" -o -path "*/production-pipeline-reports/*" | head -5 | while read report_file; do
              if [ -f "$report_file" ]; then
                echo "#### $(basename "$report_file")" >> pipeline-report.md
                STATUS=$(node -pe "try { JSON.parse(require('fs').readFileSync('$report_file', 'utf8')).summary?.overallStatus || 'unknown' } catch(e) { 'error' }")
                SUCCESS_RATE=$(node -pe "try { JSON.parse(require('fs').readFileSync('$report_file', 'utf8')).summary?.successRate || 0 } catch(e) { 0 }")
                echo "- **Status**: $STATUS" >> pipeline-report.md
                echo "- **Success Rate**: ${SUCCESS_RATE}%" >> pipeline-report.md
                echo "" >> pipeline-report.md
              fi
            done
          fi
          
          echo "### 🔗 Artifacts" >> pipeline-report.md
          echo "Generated artifacts are available in the Actions tab for 30 days." >> pipeline-report.md
          echo "" >> pipeline-report.md
          echo "---" >> pipeline-report.md
          echo "*Report generated at $(date -u)*" >> pipeline-report.md
          echo "::endgroup::"
      
      - name: 💬 Comment PR with comprehensive results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            try {
              let reportContent = '';
              
              // Main pipeline report
              const pipelineReportPath = 'pipeline-report.md';
              if (fs.existsSync(pipelineReportPath)) {
                reportContent += fs.readFileSync(pipelineReportPath, 'utf8') + '\n\n';
              }
              
              // Test report summary
              const testReportPath = 'test-report-summary.md';
              if (fs.existsSync(testReportPath)) {
                reportContent += '## 🧪 Detailed Test Results\n\n';
                reportContent += fs.readFileSync(testReportPath, 'utf8') + '\n\n';
              }
              
              // Final validation report summary
              const finalReportPath = 'final-pipeline-reports';
              if (fs.existsSync(finalReportPath)) {
                const reportFiles = fs.readdirSync(finalReportPath).filter(f => f.endsWith('.json'));
                if (reportFiles.length > 0) {
                  const latestReport = reportFiles.sort().pop();
                  const validationData = JSON.parse(fs.readFileSync(path.join(finalReportPath, latestReport), 'utf8'));
                  
                  reportContent += `## 🔍 Final Pipeline Validation\n\n`;
                  reportContent += `**Overall Status:** ${validationData.summary?.overallStatus?.toUpperCase() || 'UNKNOWN'}\n`;
                  reportContent += `**Success Rate:** ${validationData.summary?.successRate || 0}%\n`;
                  reportContent += `**Total Validations:** ${validationData.summary?.totalValidations || 0}\n`;
                  reportContent += `**Duration:** ${validationData.summary?.duration || 0}ms\n\n`;
                  
                  if (validationData.recommendations && validationData.recommendations.length > 0) {
                    reportContent += `### 💡 Pipeline Recommendations:\n`;
                    validationData.recommendations.slice(0, 5).forEach(rec => {
                      reportContent += `- **${rec.title}** (${rec.priority}): ${rec.description}\n`;
                    });
                    reportContent += '\n';
                  }
                }
              }
              
              // E2E test results summary
              const e2eFiles = ['e2e-production-results.json', 'e2e-staging-results.json'];
              for (const e2eFile of e2eFiles) {
                if (fs.existsSync(e2eFile)) {
                  const e2eData = JSON.parse(fs.readFileSync(e2eFile, 'utf8'));
                  const env = e2eFile.includes('production') ? 'Production' : 'Staging';
                  
                  reportContent += `## 🎯 ${env} E2E Test Results\n\n`;
                  reportContent += `**Status:** ${e2eData.summary?.overallStatus?.toUpperCase() || 'UNKNOWN'}\n`;
                  reportContent += `**Success Rate:** ${e2eData.summary?.successRate || 0}%\n`;
                  reportContent += `**Performance:** ${e2eData.performance?.averageResponseTime || 'N/A'}ms avg response\n`;
                  
                  if (e2eData.rollback?.triggered) {
                    reportContent += `\n⚠️ **ROLLBACK TRIGGERED:** ${e2eData.rollback.reason}\n`;
                  }
                  reportContent += '\n';
                  break; // Only show one E2E report to avoid cluttering
                }
              }
              
              if (reportContent) {
                await github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: reportContent
                });
              }
            } catch (error) {
              console.error('Failed to post PR comment:', error);
              // Post a simpler comment if the complex one fails
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: `## 🚀 CI/CD Pipeline Completed\n\n**Run ID:** ${context.runId}\n**Status:** Check the Actions tab for detailed results.`
              });
            }
      
      - name: 📊 Upload comprehensive final reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-pipeline-report-${{ github.run_id }}
          path: |
            final-pipeline-reports/
            pipeline-report.md
            test-report-*.json
            test-report-*.html
          retention-days: 30